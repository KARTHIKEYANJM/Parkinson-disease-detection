{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Detecting_Parkinson_disease.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOLu+ueDhGyRFvFBjlYfgwW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KARTHIKEYANJM/Parkinson-disease-detection/blob/main/Detecting_Parkinson_disease.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwSVlhuMuKsn"
      },
      "source": [
        "import numpy as np \r\n",
        "import cv2 as cv \r\n",
        "import os\r\n",
        "import argparse\r\n",
        "\r\n",
        "from imutils import build_montages # using build_montages for visualization\r\n",
        "from imutils import paths # using paths to extract  the file paths to each of the images in the dataset\r\n",
        "from skimage import feature # HOG comes with the feature of skimage\r\n",
        "\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "\r\n",
        "\r\n",
        "# construct the argument parser and parse the arguments\r\n",
        "# --dataset: the path to the input (waves or spirals)\r\n",
        "# --trials: number of trials to run, default = 5\r\n",
        "ap = argparse.ArgumentParser()\r\n",
        "ap.add_argument(\"-d\", \"--dataset\", required=True,\r\n",
        "            help=\"path to the input dataset\")\r\n",
        "ap.add_argument(\"-t\", \"--trials\", type=int, default=5,\r\n",
        "            help=\"number of trials to run\")\r\n",
        "args = vars(ap.parse_args())\r\n",
        "\r\n",
        "\r\n",
        "# create feature vectors using HOG \r\n",
        "def quantify_img(img):\r\n",
        "    features = feature.hog(img, orientations=9, \r\n",
        "                        pixels_per_cell=(10, 10), cells_per_block=(2,2),\r\n",
        "                        transform_sqrt=True, block_norm=\"L1\")\r\n",
        "\r\n",
        "    return features\r\n",
        "\r\n",
        "\r\n",
        "# extract data and corresponding labels from the dataset\r\n",
        "def load_split(path):\r\n",
        "    # retrieve list of paths of images in the input directory\r\n",
        "    imgPaths = list(paths.list_images(path))\r\n",
        "    \r\n",
        "    # initialize data and labels\r\n",
        "    data = []\r\n",
        "    labels = []\r\n",
        "\r\n",
        "    # loop over all the image paths\r\n",
        "    for imgPath in imgPaths:\r\n",
        "        # extract the label from the filename\r\n",
        "        label = imgPath.split(os.path.sep)[-2]\r\n",
        "\r\n",
        "        # load the input image\r\n",
        "        img = cv.imread(imgPath)\r\n",
        "\r\n",
        "        # grayscale the image\r\n",
        "        img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\r\n",
        "\r\n",
        "        # resize the image to 200x200 pixels, ignoring aspect ratio\r\n",
        "        img = cv.resize(img, (200, 200))\r\n",
        "\r\n",
        "        # threshold the image to obtain the white drawing on a black background\r\n",
        "        img = cv.threshold(img, 0, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU)[1]\r\n",
        "\r\n",
        "        # convert the img to a feature vector\r\n",
        "        img_vector = quantify_img(img)\r\n",
        "\r\n",
        "        # append img_vector and label to data and labels respectively\r\n",
        "        data.append(img_vector)\r\n",
        "        labels.append(label)\r\n",
        "\r\n",
        "    return (np.array(data), np.array(labels))\r\n",
        "\r\n",
        "\r\n",
        "# define the paths to the training and testing datasets\r\n",
        "trainingPath = os.path.sep.join([args[\"dataset\"], \"training\"])\r\n",
        "testingPath = os.path.sep.join([args[\"dataset\"], \"testing\"])\r\n",
        "\r\n",
        "# loading training and testing datasets\r\n",
        "print(\"Loading data...\")\r\n",
        "(trainX, trainY) = load_split(trainingPath)\r\n",
        "(testX, testY) = load_split(testingPath)\r\n",
        "\r\n",
        "# encode the labels\r\n",
        "le = LabelEncoder()\r\n",
        "trainY = le.fit_transform(trainY)\r\n",
        "testY = le.transform(testY)\r\n",
        "\r\n",
        "# initialize our trials dictionary\r\n",
        "trials = {}\r\n",
        "\r\n",
        "# loop over all the number of trials\r\n",
        "for i in range(args[\"trials\"]):\r\n",
        "    # train the model\r\n",
        "    print(\"Training model {} of {}...\".format(i+1, args[\"trials\"]))\r\n",
        "    model = RandomForestClassifier(n_estimators=100)\r\n",
        "    model.fit(trainX, trainY)\r\n",
        "\r\n",
        "    # make predictions on the testing dataset\r\n",
        "    preds = model.predict(testX)\r\n",
        "    metrics = {}\r\n",
        "\r\n",
        "    # compute the confusion matrix\r\n",
        "    cm = confusion_matrix(testY, preds).flatten()\r\n",
        "    (tn, fp, fn, tp) = cm\r\n",
        "    metrics[\"acc\"] = (tp + tn) / float(cm.sum())\r\n",
        "    metrics[\"sensitivity\"] = tp / float(tp + fn)\r\n",
        "    metrics[\"specificity\"] = tn / float(tn + fp)\r\n",
        "\r\n",
        "    # loop over the metrics\r\n",
        "    for (k, v) in metrics.items():\r\n",
        "        # update the trials dictionary with the list of values for the current metric\r\n",
        "        l = trials.get(k, [])\r\n",
        "        l.append(v)\r\n",
        "        trials[k] = l\r\n",
        "\r\n",
        "for metric in (\"acc\", \"sensitivity\", \"specificity\"):\r\n",
        "    # get the list of values for the current metric and computer mean and stdv\r\n",
        "    values = trials[metric]\r\n",
        "    mean = np.mean(values)\r\n",
        "    stdv = np.std(values)\r\n",
        "\r\n",
        "    print(metric)\r\n",
        "    print(\"=\" * len(metric))\r\n",
        "    print(\"u={:.4f}, o={:.4f}\".format(mean, stdv))\r\n",
        "    print(\"\")\r\n",
        "\r\n",
        "\r\n",
        "# randomly select a few images \r\n",
        "testingPaths = list(paths.list_images(testingPath))\r\n",
        "idxs = np.arange(0, len(testingPaths))\r\n",
        "idxs = np.random.choice(idxs, size=(25,), replace=False)\r\n",
        "\r\n",
        "imgs = []\r\n",
        "\r\n",
        "for i in idxs:\r\n",
        "    # preprocess the testing image same as above\r\n",
        "    img = cv.imread(testingPaths[i])\r\n",
        "    output = img.copy()\r\n",
        "    output = cv.resize(output, (128, 128))\r\n",
        "    \r\n",
        "    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\r\n",
        "    img = cv.resize(img, (200, 200))\r\n",
        "    img = cv.threshold(img, 0, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU)[1]\r\n",
        "\r\n",
        "    # create a feature vector from the testing image\r\n",
        "    features = quantify_img(img)\r\n",
        "    preds = model.predict([features])\r\n",
        "    label = le.inverse_transform(preds)[0]\r\n",
        "\r\n",
        "    # draw the colored class label on the output and add to the set of outputs\r\n",
        "    green = (0, 255, 0) \r\n",
        "    red = (0, 0, 255)\r\n",
        "\r\n",
        "    color = green if label == \"healthy\" else red\r\n",
        "    cv.putText(output, label, (3, 20), cv.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\r\n",
        "    imgs.append(output)\r\n",
        "\r\n",
        "# take a list of imgs and create a montage with size 5x5 and resize all the images inside to 128x128 \r\n",
        "montage = build_montages(imgs, (128, 128), (5, 5))[0]\r\n",
        "\r\n",
        "# show the output montage\r\n",
        "cv.imshow(\"Output\", montage)\r\n",
        "cv.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edor_G7BumkQ",
        "outputId": "99d3a768-2929-4b9c-db31-b630d9284e5a"
      },
      "source": [
        "!python main.py -d /content/Parkinson_detection/data/wave"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Training model 1 of 5...\n",
            "Training model 2 of 5...\n",
            "Training model 3 of 5...\n",
            "Training model 4 of 5...\n",
            "Training model 5 of 5...\n",
            "acc\n",
            "===\n",
            "u=0.7000, o=0.0471\n",
            "\n",
            "sensitivity\n",
            "===========\n",
            "u=0.7067, o=0.0680\n",
            "\n",
            "specificity\n",
            "===========\n",
            "u=0.6933, o=0.0533\n",
            "\n",
            ": cannot connect to X server \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Kuwr9U1wf_E",
        "outputId": "179fbdda-3add-4ec6-95ee-26a927c2f09c"
      },
      "source": [
        "%cd \"/content/Parkinson_detection/\""
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Parkinson_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32PeS0J7wkZ9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}